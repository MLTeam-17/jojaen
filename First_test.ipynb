{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Data불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#데이터 불러오기\n",
    "try:\n",
    "    data1 = pd.read_csv('Data/sample_submission.csv', encoding='utf-8')\n",
    "    data2 = pd.read_csv('Data/test.csv', encoding='utf-8')\n",
    "    data3 = pd.read_csv('Data/train.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    #UTF-8로 실패한 경우 CP949로 재시도\n",
    "    data1 = pd.read_csv('Data/sample_submission.csv', encoding='cp949')\n",
    "    data2 = pd.read_csv('Data/test.csv', encoding='utf-8')\n",
    "    data3 = pd.read_csv('Data/train.csv', encoding='utf-8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_id</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>block</th>\n",
       "      <th>street</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>commence_date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199577</td>\n",
       "      <td>2006-09</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>107D</td>\n",
       "      <td>Agawan Court</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>110.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2003</td>\n",
       "      <td>313000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217021</td>\n",
       "      <td>2007-06</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>678</td>\n",
       "      <td>Cleo St</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>64.0</td>\n",
       "      <td>N</td>\n",
       "      <td>1988</td>\n",
       "      <td>167000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308062</td>\n",
       "      <td>2010-09</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>5</td>\n",
       "      <td>E Pleasant View Way</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>92.0</td>\n",
       "      <td>K</td>\n",
       "      <td>1976</td>\n",
       "      <td>430000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212465</td>\n",
       "      <td>2007-04</td>\n",
       "      <td>Austin</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>326</td>\n",
       "      <td>Park Hollow Ln</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>92.0</td>\n",
       "      <td>K</td>\n",
       "      <td>1977</td>\n",
       "      <td>303800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60654</td>\n",
       "      <td>2001-10</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>794</td>\n",
       "      <td>Ala Puawa Place</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>102.0</td>\n",
       "      <td>G</td>\n",
       "      <td>1998</td>\n",
       "      <td>212000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_id     date  location    type block               street  \\\n",
       "0    199577  2006-09   Raleigh  5 ROOM  107D       Agawan Court     \n",
       "1    217021  2007-06    Fresno  3 ROOM   678              Cleo St   \n",
       "2    308062  2010-09    Tucson  4 ROOM     5  E Pleasant View Way   \n",
       "3    212465  2007-04    Austin  4 ROOM   326       Park Hollow Ln   \n",
       "4     60654  2001-10  Honolulu  4 ROOM   794    Ala Puawa Place     \n",
       "\n",
       "  storey_range  area_sqm flat_model  commence_date     price  \n",
       "0     07 TO 09     110.0          D           2003  313000.0  \n",
       "1     07 TO 09      64.0          N           1988  167000.0  \n",
       "2     10 TO 12      92.0          K           1976  430000.0  \n",
       "3     10 TO 12      92.0          K           1977  303800.0  \n",
       "4     04 TO 06     102.0          G           1998  212000.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()\n",
    "data2.head()\n",
    "data3.head()\n",
    "data1.tail()\n",
    "data2.tail()\n",
    "data3.tail()\n",
    "\n",
    "#data1: house_id\tprice\n",
    "#data2:\thouse_id\tdate\tlocation\ttype\tblock\tstreet\tstorey_range\tarea_sqm\tflat_model\tcommence_date\n",
    "#data3:\thouse_id\tdate\tlocation\ttype\tblock\tstreet\tstorey_range\tarea_sqm\tflat_model\tcommence_date\tprice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv file 인코딩 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "    return result['encoding']\n",
    "\n",
    "def convert_to_utf8(file_path, output_path):\n",
    "    encoding = detect_encoding(file_path)\n",
    "    with open(file_path, 'r', encoding=encoding) as f:\n",
    "        content = f.read()\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "# 파일 인코딩 확인 및 변환\n",
    "file_paths = ['Data/sample_submission.csv', 'Data/test.csv', 'Data/train.csv']\n",
    "output_paths = ['data1_utf8.csv', 'data2_utf8.csv', 'data3_utf8.csv']\n",
    "\n",
    "for file_path, output_path in zip(file_paths, output_paths):\n",
    "    convert_to_utf8(file_path, output_path)\n",
    "\n",
    "# 변환된 파일을 다시 읽어오기\n",
    "try:\n",
    "    data1 = pd.read_csv('data1_utf8.csv', encoding='utf-8')\n",
    "    data2 = pd.read_csv('data2_utf8.csv', encoding='utf-8')\n",
    "    data3 = pd.read_csv('data3_utf8.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"Error reading the files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['house_id', 'price'],\n",
      "        num_rows: 67930\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date'],\n",
      "        num_rows: 67930\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price'],\n",
      "        num_rows: 271721\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#로컬 csv파일 로드\n",
    "dataset1 = load_dataset('csv', data_files='Data/data1_utf8.csv')\n",
    "dataset2 = load_dataset('csv', data_files='Data/data2_utf8.csv')\n",
    "dataset3 = load_dataset('csv', data_files='Data/data3_utf8.csv')\n",
    "\n",
    "print(dataset1, dataset2, dataset3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO: datasets 라이브러리는 주로 자연어 처리(NLP)와 관련된 데이터셋을 다루기 위해 사용됩니다. 이 라이브러리에서는 Dataset 객체를 생성할 때 일반적으로 train, validation, test와 같은 분할을 사용합니다. 따라서, train은 데이터셋의 특정 분할을 나타내기 위한 것이며, 개별 컬럼이 아닙니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset1['train'])\n",
    "type(dataset2['train'])\n",
    "type(dataset3['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset1['train']['house_id'])\n",
    "type(dataset2['train']['house_id'])\n",
    "type(dataset3['train']['house_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'house_id': 2, 'price': 150000}\n",
      "{'house_id': 2, 'date': '2000-01', 'location': 'Austin', 'type': '3 ROOM', 'block': '174', 'street': 'Governors Row', 'storey_range': '04 TO 06', 'area_sqm': 61.0, 'flat_model': 'D', 'commence_date': 1986}\n",
      "{'house_id': 199577, 'date': '2006-09', 'location': 'Raleigh', 'type': '5 ROOM', 'block': '107D', 'street': 'Agawan Court  ', 'storey_range': '07 TO 09', 'area_sqm': 110.0, 'flat_model': 'D', 'commence_date': 2003, 'price': 313000.0}\n"
     ]
    }
   ],
   "source": [
    "print(dataset1['train'][0])\n",
    "print(dataset2['train'][0])\n",
    "print(dataset3['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'house_id': 199577, 'date': '2006-09', 'location': 'Raleigh', 'type': '5 ROOM', 'block': '107D', 'street': 'Agawan Court  ', 'storey_range': '07 TO 09', 'area_sqm': 110.0, 'flat_model': 'D', 'commence_date': 2003, 'price': 313000.0}\n",
      "{'house_id': 217021, 'date': '2007-06', 'location': 'Fresno', 'type': '3 ROOM', 'block': '678', 'street': 'Cleo St', 'storey_range': '07 TO 09', 'area_sqm': 64.0, 'flat_model': 'N', 'commence_date': 1988, 'price': 167000.0}\n",
      "{'house_id': 308062, 'date': '2010-09', 'location': 'Tucson', 'type': '4 ROOM', 'block': '5', 'street': 'E Pleasant View Way', 'storey_range': '10 TO 12', 'area_sqm': 92.0, 'flat_model': 'K', 'commence_date': 1976, 'price': 430000.0}\n",
      "{'house_id': 212465, 'date': '2007-04', 'location': 'Austin', 'type': '4 ROOM', 'block': '326', 'street': 'Park Hollow Ln', 'storey_range': '10 TO 12', 'area_sqm': 92.0, 'flat_model': 'K', 'commence_date': 1977, 'price': 303800.0}\n",
      "{'house_id': 60654, 'date': '2001-10', 'location': 'Honolulu', 'type': '4 ROOM', 'block': '794', 'street': 'Ala Puawa Place  ', 'storey_range': '04 TO 06', 'area_sqm': 102.0, 'flat_model': 'G', 'commence_date': 1998, 'price': 212000.0}\n",
      "{'house_id': 193658, 'date': '2006-06', 'location': 'Riverside', 'type': '4 ROOM', 'block': '296', 'street': 'Jay Ct', 'storey_range': '07 TO 09', 'area_sqm': 90.0, 'flat_model': 'G', 'commence_date': 2000, 'price': 248000.0}\n",
      "{'house_id': 236233, 'date': '2008-03', 'location': 'Omaha', 'type': '4 ROOM', 'block': '214', 'street': 'Bauman Ave', 'storey_range': '10 TO 12', 'area_sqm': 106.0, 'flat_model': 'G', 'commence_date': 1993, 'price': 295000.0}\n",
      "{'house_id': 264915, 'date': '2009-05', 'location': 'Fresno', 'type': '4 ROOM', 'block': '555', 'street': 'Triple Glen Ct', 'storey_range': '01 TO 03', 'area_sqm': 103.0, 'flat_model': 'G', 'commence_date': 1992, 'price': 294000.0}\n",
      "{'house_id': 40057, 'date': '2001-03', 'location': 'Riverside', 'type': '5 ROOM', 'block': '413', 'street': 'Laredo Rd', 'storey_range': '04 TO 06', 'area_sqm': 123.0, 'flat_model': 'D', 'commence_date': 1993, 'price': 320000.0}\n",
      "{'house_id': 106886, 'date': '2003-04', 'location': 'Washington', 'type': '4 ROOM', 'block': '102', 'street': 'High View Ter SE  ', 'storey_range': '04 TO 06', 'area_sqm': 80.0, 'flat_model': 'O', 'commence_date': 1970, 'price': 235000.0}\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for sample in dataset3['train']:\n",
    "    print(sample)\n",
    "    cnt +=1\n",
    "    if cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 버전 추가해서 업로드하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 전처리/수정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price'],\n",
       "    num_rows: 271721\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1['train']\n",
    "dataset2['train']\n",
    "dataset3['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_id</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>block</th>\n",
       "      <th>street</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>area_sqm</th>\n",
       "      <th>flat_model</th>\n",
       "      <th>commence_date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199577</td>\n",
       "      <td>2006-09</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>5 ROOM</td>\n",
       "      <td>107D</td>\n",
       "      <td>Agawan Court</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>110.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2003</td>\n",
       "      <td>313000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217021</td>\n",
       "      <td>2007-06</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>3 ROOM</td>\n",
       "      <td>678</td>\n",
       "      <td>Cleo St</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>64.0</td>\n",
       "      <td>N</td>\n",
       "      <td>1988</td>\n",
       "      <td>167000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308062</td>\n",
       "      <td>2010-09</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>5</td>\n",
       "      <td>E Pleasant View Way</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>92.0</td>\n",
       "      <td>K</td>\n",
       "      <td>1976</td>\n",
       "      <td>430000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212465</td>\n",
       "      <td>2007-04</td>\n",
       "      <td>Austin</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>326</td>\n",
       "      <td>Park Hollow Ln</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>92.0</td>\n",
       "      <td>K</td>\n",
       "      <td>1977</td>\n",
       "      <td>303800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60654</td>\n",
       "      <td>2001-10</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>4 ROOM</td>\n",
       "      <td>794</td>\n",
       "      <td>Ala Puawa Place</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>102.0</td>\n",
       "      <td>G</td>\n",
       "      <td>1998</td>\n",
       "      <td>212000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   house_id     date  location    type block               street  \\\n",
       "0    199577  2006-09   Raleigh  5 ROOM  107D       Agawan Court     \n",
       "1    217021  2007-06    Fresno  3 ROOM   678              Cleo St   \n",
       "2    308062  2010-09    Tucson  4 ROOM     5  E Pleasant View Way   \n",
       "3    212465  2007-04    Austin  4 ROOM   326       Park Hollow Ln   \n",
       "4     60654  2001-10  Honolulu  4 ROOM   794    Ala Puawa Place     \n",
       "\n",
       "  storey_range  area_sqm flat_model  commence_date     price  \n",
       "0     07 TO 09     110.0          D           2003  313000.0  \n",
       "1     07 TO 09      64.0          N           1988  167000.0  \n",
       "2     10 TO 12      92.0          K           1976  430000.0  \n",
       "3     10 TO 12      92.0          K           1977  303800.0  \n",
       "4     04 TO 06     102.0          G           1998  212000.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset -> dataframe 형태로 변환\n",
    "df1 = pd.DataFrame(dataset1['train'])\n",
    "df2 = pd.DataFrame(dataset2['train'])\n",
    "df3 = pd.DataFrame(dataset3['train'])\n",
    "\n",
    "df1.head()\n",
    "df2.head()\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_id    0\n",
      "price       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#결측치 확인\n",
    "print(df1.isnull().sum())\n",
    "print(df2.isnull().sum())\n",
    "print(df3.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#수치형 열만 선택\n",
    "numerical_column1 = df1.select_dtypes(include = 'number').columns\n",
    "numerical_column2 = df2.select_dtypes(include = 'number').columns\n",
    "numerical_column3 = df3.select_dtypes(include = 'number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 대체(수치형 열에만 적용)\n",
    "df1[numerical_column1] = df1[numerical_column1].fillna(df1[numerical_column1].mean())\n",
    "df2[numerical_column2] = df2[numerical_column2].fillna(df2[numerical_column2].mean())\n",
    "df3[numerical_column3] = df3[numerical_column3].fillna(df3[numerical_column3].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_id</th>\n",
       "      <th>area_sqm</th>\n",
       "      <th>commence_date</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587593</td>\n",
       "      <td>0.325397</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.325714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638952</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.158857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.906995</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.459429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.625538</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.315200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.178575</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.210286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271716</th>\n",
       "      <td>0.299020</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.233143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271717</th>\n",
       "      <td>0.083309</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271718</th>\n",
       "      <td>0.948017</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.595301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271719</th>\n",
       "      <td>0.907290</td>\n",
       "      <td>0.246032</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.379429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271720</th>\n",
       "      <td>0.664478</td>\n",
       "      <td>0.456349</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.482286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271721 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        house_id  area_sqm  commence_date     price\n",
       "0       0.587593  0.325397       0.840909  0.325714\n",
       "1       0.638952  0.142857       0.500000  0.158857\n",
       "2       0.906995  0.253968       0.227273  0.459429\n",
       "3       0.625538  0.253968       0.250000  0.315200\n",
       "4       0.178575  0.293651       0.727273  0.210286\n",
       "...          ...       ...            ...       ...\n",
       "271716  0.299020  0.297619       0.522727  0.233143\n",
       "271717  0.083309  0.420635       0.681818  0.457143\n",
       "271718  0.948017  0.357143       0.863636  0.595301\n",
       "271719  0.907290  0.246032       0.750000  0.379429\n",
       "271720  0.664478  0.456349       0.613636  0.482286\n",
       "\n",
       "[271721 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#정규화\n",
    "scaler = MinMaxScaler()\n",
    "df1[numerical_column1] = scaler.fit_transform(df1[numerical_column1])\n",
    "df2[numerical_column2] = scaler.fit_transform(df2[numerical_column2])\n",
    "df3[numerical_column3] = scaler.fit_transform(df3[numerical_column3])\n",
    "\n",
    "df1[numerical_column1]\n",
    "df2[numerical_column2]\n",
    "df3[numerical_column3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수정된 데이터셋 태그 붙여서 업로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price'],\n",
       "        num_rows: 271721\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "dataset1 = Dataset.from_pandas(df1)\n",
    "dataset2 = Dataset.from_pandas(df2)\n",
    "dataset3 = Dataset.from_pandas(df3)\n",
    "\n",
    "#데이터셋을 DatasetDict로 변환\n",
    "dataset_dict1 = DatasetDict({\"train\":dataset1})\n",
    "dataset_dict2 = DatasetDict({\"train\":dataset2})\n",
    "dataset_dict3 = DatasetDict({\"train\":dataset3})\n",
    "\n",
    "dataset_dict1\n",
    "dataset_dict2\n",
    "dataset_dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#데이터 분할(train: 80%, validation: 10%, test: 10%)\n",
    "train_df1, temp_df1 = train_test_split(df1, test_size=0.2, random_state=42)\n",
    "validation_df1, test_df1 = train_test_split(temp_df1, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df2, temp_df2 = train_test_split(df2, test_size=0.2, random_state=42)\n",
    "validation_df2, test_df2 = train_test_split(temp_df2, test_size=0.5, random_state=42)\n",
    "\n",
    "train_df3, temp_df3 = train_test_split(df3, test_size=0.2, random_state=42)\n",
    "validation_df3, test_df3 = train_test_split(temp_df3, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "#데이터 프레임을 Dataset으로 변환\n",
    "train_dataset1 = Dataset.from_pandas(train_df1)\n",
    "validation_dataset1 = Dataset.from_pandas(validation_df1)\n",
    "test_dataset1 = Dataset.from_pandas(test_df1)\n",
    "\n",
    "train_dataset2 = Dataset.from_pandas(train_df2)\n",
    "validation_dataset2 = Dataset.from_pandas(validation_df2)\n",
    "test_dataset2 = Dataset.from_pandas(test_df2)\n",
    "\n",
    "train_dataset3 = Dataset.from_pandas(train_df3)\n",
    "validation_dataset3 = Dataset.from_pandas(validation_df3)\n",
    "test_dataset3 = Dataset.from_pandas(test_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price', '__index_level_0__'],\n",
       "    num_rows: 27173\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset1\n",
    "test_dataset2\n",
    "test_dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하나로 합치기\n",
    "final_dataset1 = DatasetDict({\n",
    "    \"train\" : train_dataset1,\n",
    "    \"validation\" : validation_dataset1,\n",
    "    \"test\" : test_dataset1 \n",
    "})\n",
    "final_dataset2 = DatasetDict({\n",
    "    \"train\" : train_dataset2,\n",
    "    \"validation\" : validation_dataset2,\n",
    "    \"test\" : test_dataset2 \n",
    "})\n",
    "final_dataset3 = DatasetDict({\n",
    "    \"train\" : train_dataset3,\n",
    "    \"validation\" : validation_dataset3,\n",
    "    \"test\" : test_dataset3 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['house_id', 'price', '__index_level_0__'],\n",
      "        num_rows: 54344\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['house_id', 'price', '__index_level_0__'],\n",
      "        num_rows: 6793\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['house_id', 'price', '__index_level_0__'],\n",
      "        num_rows: 6793\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', '__index_level_0__'],\n",
      "        num_rows: 54344\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', '__index_level_0__'],\n",
      "        num_rows: 6793\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', '__index_level_0__'],\n",
      "        num_rows: 6793\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price', '__index_level_0__'],\n",
      "        num_rows: 217376\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price', '__index_level_0__'],\n",
      "        num_rows: 27172\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['house_id', 'date', 'location', 'type', 'block', 'street', 'storey_range', 'area_sqm', 'flat_model', 'commence_date', 'price', '__index_level_0__'],\n",
      "        num_rows: 27173\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#분할 된 데이터셋 확인\n",
    "print(final_dataset1)\n",
    "print(final_dataset2)\n",
    "print(final_dataset3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "이제 데이터셋이 준비되었으므로, 다음 단계는 모델을 학습하고 평가하는 것입니다. 데이터셋을 사용하여 모델을 학습하려면 먼저 모델을 선택하고 적절한 입력 형식으로 데이터셋을 변환해야 합니다. 그런 다음 변환된 데이터셋을 사용하여 모델을 학습하고 평가합니다.\n",
    "\n",
    "여기서는 간단한 분류 문제를 예로 들겠습니다. 주어진 데이터로 주택 가격을 예측하는 문제라고 가정해 보겠습니다. 다음은 기본적인 모델 학습 및 평가 프로세스입니다.\n",
    "\n",
    "1. 모델 선택\n",
    "모델을 선택해야 합니다. 예를 들어, 이러한 유형의 문제에는 선형 회귀, 결정 트리, 랜덤 포레스트 등의 모델이 사용될 수 있습니다.\n",
    "\n",
    "2. 입력 데이터 변환\n",
    "데이터셋을 모델에 입력할 수 있는 형식으로 변환해야 합니다. 이는 주로 입력 특성을 정규화하거나 인코딩하는 등의 작업을 포함합니다. 데이터셋이 이미 적절한 형식으로 준비되어 있으므로 이 단계는 건너뛸 수 있습니다.\n",
    "\n",
    "3. 모델 학습\n",
    "선택한 모델을 데이터셋을 사용하여 학습합니다. 학습된 모델은 훈련 데이터에 대해 적합한 모델 파라미터를 가지게 됩니다.\n",
    "\n",
    "4. 모델 평가\n",
    "학습된 모델을 검증 및 테스트 데이터셋에 적용하여 모델의 성능을 평가합니다. 성능 메트릭에는 정확도, 정밀도, 재현율, F1 점수 등이 포함될 수 있습니다.\n",
    "\n",
    "다음은 이러한 단계를 구체적으로 수행하는 예시 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0\n",
      "Validation Score: 1.0\n",
      "Test Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. 모델 선택\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. 모델 학습\n",
    "model.fit(final_dataset1['train'].to_pandas(), final_dataset1['train']['price'])\n",
    "\n",
    "# 4. 모델 평가\n",
    "train_score1 = model.score(final_dataset1['train'].to_pandas(), final_dataset1['train']['price'])\n",
    "validation_score1 = model.score(final_dataset1['validation'].to_pandas(), final_dataset1['validation']['price'])\n",
    "test_score1 = model.score(final_dataset1['test'].to_pandas(), final_dataset1['test']['price'])\n",
    "\n",
    "print(\"Train Score:\", train_score1)\n",
    "print(\"Validation Score:\", validation_score1)\n",
    "print(\"Test Score:\", test_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2010-06'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 3. 모델 학습\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_dataset2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_dataset2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhouse_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 4. 모델 평가\u001b[39;00m\n\u001b[0;32m     10\u001b[0m train_score2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(final_dataset2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_pandas(), final_dataset2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhouse_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    574\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    576\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 578\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:2153\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\n\u001b[0;32m   2150\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2152\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 2153\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2155\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2158\u001b[0m     ):\n\u001b[0;32m   2159\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2160\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2161\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2162\u001b[0m         ):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2010-06'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. 모델 선택\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. 모델 학습\n",
    "model.fit(final_dataset2['train'].to_pandas(), final_dataset2['train']['house_id'])\n",
    "\n",
    "# 4. 모델 평가\n",
    "train_score2 = model.score(final_dataset2['train'].to_pandas(), final_dataset2['train']['house_id'])\n",
    "validation_score2 = model.score(final_dataset2['validation'].to_pandas(), final_dataset2['validation']['house_id'])\n",
    "test_score2 = model.score(final_dataset2['test'].to_pandas(), final_dataset2['test']['house_id'])\n",
    "\n",
    "print(\"Train Score:\", train_score2)\n",
    "print(\"Validation Score:\", validation_score2)\n",
    "print(\"Test Score:\", test_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2000-03'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 3. 모델 학습\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_dataset3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_dataset3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 4. 모델 평가\u001b[39;00m\n\u001b[0;32m     10\u001b[0m train_score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(final_dataset3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_pandas(), final_dataset3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:578\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    574\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    576\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 578\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32mc:\\Users\\cchok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:2153\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\n\u001b[0;32m   2150\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2152\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 2153\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2155\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2158\u001b[0m     ):\n\u001b[0;32m   2159\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2160\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2161\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2162\u001b[0m         ):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2000-03'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1. 모델 선택\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. 모델 학습\n",
    "model.fit(final_dataset3['train'].to_pandas(), final_dataset3['train']['price'])\n",
    "\n",
    "# 4. 모델 평가\n",
    "train_score = model.score(final_dataset3['train'].to_pandas(), final_dataset3['train']['price'])\n",
    "validation_score = model.score(final_dataset3['validation'].to_pandas(), final_dataset3['validation']['price'])\n",
    "test_score = model.score(final_dataset3['test'].to_pandas(), final_dataset3['test']['price'])\n",
    "\n",
    "print(\"Train Score:\", train_score)\n",
    "print(\"Validation Score:\", validation_score)\n",
    "print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드에서 LinearRegression 모델을 선택하고, final_dataset1['train']을 학습 데이터로 사용하여 모델을 학습하고, 각 데이터셋에 대해 R^2 점수를 계산하여 모델의 성능을 평가합니다. 위 코드를 각 데이터셋(final_dataset1, final_dataset2, final_dataset3)에 대해 반복 적용하여 모든 데이터셋에 대한 모델 성능을 비교할 수 있습니다.\n",
    "\n",
    "이 코드를 실행하여 모델을 학습하고 평가해보세요. 필요에 따라 모델 선택 및 평가 메트릭을 수정할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
